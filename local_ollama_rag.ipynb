{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm\",\n",
    "]\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "# Create embeddings for documents and store them in a vector store\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OllamaEmbeddings(\n",
    "    model=\"deepseek-r1:32b\"\n",
    ")\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template for the LLM\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with Llama 3.1 model\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:32b\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain combining the prompt template and LLM\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG application class\n",
    "class RAGApplication:\n",
    "    def __init__(self, retriever, rag_chain):\n",
    "        self.retriever = retriever\n",
    "        self.rag_chain = rag_chain\n",
    "    def run(self, question):\n",
    "        # Retrieve relevant documents\n",
    "        documents = self.retriever.invoke(question)\n",
    "        # Extract content from retrieved documents\n",
    "        doc_texts = \"\\\\n\".join([doc.page_content for doc in documents])\n",
    "        # Get the answer from the language model\n",
    "        answer = self.rag_chain.invoke({\"question\": question, \"documents\": doc_texts})\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special encoding: Adversarial inputs use Base64 encoding.\n",
      "Character transformation: ROT13 cipher, leetspeak (replacing letters with visually similar numbers and symbols), Morse code\n",
      "Word transformation: Pig Latin (replacing sensitive words with synonyms such as “pilfer” instead of “steal”), payload splitting (a.k.a. “token smuggling” to split sensitive words into substrings).\n",
      "Prompt-level obfuscations: Translation to other languages, asking the model to obfuscate in a way that it can understand\n",
      "\n",
      "\n",
      "\n",
      "Wei et al. (2023)  experimented a large of jailbreak methods, including combined strategies, constructed by following the above principles.\n",
      "\n",
      "combination_1 composes prefix injection, refusal suppression, and the Base64 attack\n",
      "combination_2 adds style injection\n",
      "combination_3 adds generating website content and formatting constraints\\nText: i'll bet the video game is a lot more fun than the film. \n",
      "Sentiment:\n",
      "Explaining the desired audience is another smart way to give instructions\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\n",
      "Zero-Shot#\n",
      "Zero-shot learning is to simply feed the task text to the model and ask for results.\n",
      "(All the sentiment analysis examples are from SST-2)\n",
      "Text: i'll bet the video game is a lot more fun than the film.\n",
      "Sentiment:\n",
      "Few-shot#\n",
      "Few-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\n",
      "Text: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\n",
      "Sentiment: positive\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$\n",
      "Question: What is prompt engineering\n",
      "Answer: <think>\n",
      "Okay, so I need to figure out what prompt engineering is based on the given documents. Let me start by reading through the provided information carefully.\n",
      "\n",
      "The first part talks about different methods used in prompt engineering, like special encoding with Base64 and character transformations such as ROT13 or leetspeak. There are also word transformations mentioned, including Pig Latin and payload splitting. Then it goes into prompt-level obfuscations, which involve translating prompts into other languages or making the model understand them through obfuscation.\n",
      "\n",
      "Looking further, there's a mention of Wei et al. (2023) experimenting with various jailbreak methods using combinations of these strategies. The document also explains zero-shot and few-shot learning approaches for prompting models, where zero-shot involves giving the task directly without examples, while few-shot provides examples to help the model understand better.\n",
      "\n",
      "Additionally, there's a section on Chain of Hindsight (CoH), which uses past outputs with feedback to improve model performance through supervised fine-tuning. This seems like another aspect of prompt engineering as it involves refining prompts based on previous interactions and feedback.\n",
      "\n",
      "Putting this together, prompt engineering appears to be the practice of crafting effective prompts for language models by using various techniques to enhance understanding, avoid detection, or improve output quality. It includes encoding methods, transformation strategies, obfuscation at different levels, and learning approaches like zero-shot and few-shot prompting.\n",
      "</think>\n",
      "\n",
      "Prompt engineering is the process of designing effective prompts for language models, utilizing techniques such as encoding, transformations, and learning strategies (zero-shot, few-shot) to enhance understanding or output quality. It involves methods like Base64 encoding, ROT13 cipher, Pig Latin, and feedback mechanisms to refine model responses.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG application\n",
    "rag_application = RAGApplication(retriever, rag_chain)\n",
    "# Example usage\n",
    "question = \"What is prompt engineering\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
